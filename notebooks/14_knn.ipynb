{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distance_ = cp.RawKernel(\n",
    "    r'''\n",
    "    extern \"C\" __global__\n",
    "    void kernel(const float* inp_a,\n",
    "                const float* inp_b,\n",
    "                float* outp,\n",
    "                const int n, const int m, const int k) {\n",
    "        int grid_x = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        int grid_y = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "        int grid_xy = grid_x + grid_y * n;\n",
    "        \n",
    "        if (grid_x < n && grid_y < m) {\n",
    "            float dist = 0;\n",
    "            for ( int i = 0; i < k; i++) {\n",
    "                const float d = (inp_a[grid_x * k + i] - inp_b[grid_y * k + i]);\n",
    "                dist += (d * d);\n",
    "            }\n",
    "            outp[grid_xy] = dist;  // Store squared Euclidean distance\n",
    "        }\n",
    "    }\n",
    "    ''', \n",
    "    \"kernel\"\n",
    ")\n",
    "\n",
    "def distance(inp_a: np.ndarray, inp_b: np.ndarray) -> np.ndarray:\n",
    "    n, k_ = inp_a.shape\n",
    "    m, k = inp_b.shape\n",
    "    assert k_ == k\n",
    "\n",
    "    inp_a = inp_a.astype('float32')\n",
    "    inp_b = inp_b.astype('float32')\n",
    "    outp = cp.zeros((n, m), dtype=cp.float32)\n",
    "\n",
    "    block_size_x, block_size_y = 32, 32\n",
    "    grid_size_x = (n + block_size_x - 1) // block_size_x\n",
    "    grid_size_y = (m + block_size_y - 1) // block_size_y\n",
    "\n",
    "    inp_a = cp.asarray(inp_a, dtype=cp.float32)\n",
    "    inp_b = cp.asarray(inp_b, dtype=cp.float32)\n",
    "    \n",
    "    distance_( \n",
    "        (grid_size_x, grid_size_y),\n",
    "        (block_size_x, block_size_y),\n",
    "        (\n",
    "            inp_a, inp_b,\n",
    "            outp, \n",
    "            cp.int32(n), cp.int32(m), cp.int32(k)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    outp = cp.sqrt(outp)  # Take square root after copying back to host\n",
    "    return np.array(outp.get())\n",
    "\n",
    "# Define array sizes for testing\n",
    "array_sizes = [250, 500, 1000, 2000, 4000, 8000, 16000]\n",
    "\n",
    "# Measure execution time for each array size\n",
    "execution_times = []\n",
    "for size in array_sizes:\n",
    "    inp_a = np.random.randn(size, 10).astype('float32')\n",
    "    inp_b = np.random.randn(size, 10).astype('float32')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    out = distance(inp_a, inp_b)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    execution_time = end_time - start_time\n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "# Plotting\n",
    "plt.loglog(array_sizes, execution_times, marker='o')\n",
    "plt.title('Performance of KNN Distance Algorithm')\n",
    "plt.xlabel('Array Size')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.233449,0.166667,0.381818,0.424594,0.164110,0.354839,0.250000,0.325581,0.166184,0.192771,6.000000\n",
      "0.160279,0.196078,0.263636,0.262181,0.176380,0.161290,0.346154,0.255814,0.196453,0.301205,5.000000\n",
      "0.083624,0.156863,0.300000,0.396752,0.191718,0.177419,0.355769,0.360465,0.226141,0.186747,6.000000\n",
      "0.097561,0.107843,0.390909,0.201856,0.019939,0.451613,0.288462,0.372093,0.088490,0.216867,7.000000\n",
      "0.073171,0.411765,0.445455,0.271462,0.007669,0.467742,0.413462,0.232558,0.128976,0.283133,5.000000\n",
      "0.111498,0.235294,0.454545,0.197216,0.062883,0.822581,0.201923,0.406977,0.048775,0.168675,7.000000\n",
      "0.024390,0.107843,0.309091,0.213457,0.015337,0.500000,0.442308,0.500000,0.132832,0.253012,4.000000\n",
      "0.118467,0.127451,0.363636,0.262181,0.151840,0.419355,0.326923,0.209302,0.147869,0.186747,6.000000\n",
      "0.108014,0.225490,0.290909,0.248260,0.185583,0.387097,0.298077,0.500000,0.159823,0.198795,6.000000\n",
      "0.149826,0.137255,0.445455,0.357309,0.214724,0.096774,0.403846,0.546512,0.254290,0.253012,7.000000\n"
     ]
    }
   ],
   "source": [
    "! head store/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.233449</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.424594</td>\n",
       "      <td>0.164110</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160279</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.262181</td>\n",
       "      <td>0.176380</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.196453</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.396752</td>\n",
       "      <td>0.191718</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.201856</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.088490</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.445455</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.216028</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.415313</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.202091</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.278422</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.144399</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.292343</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.103913</td>\n",
       "      <td>0.162651</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.216028</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.443155</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.164064</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feat0     feat1     feat2     feat3     feat4     feat5     feat6  \\\n",
       "0     0.233449  0.166667  0.381818  0.424594  0.164110  0.354839  0.250000   \n",
       "1     0.160279  0.196078  0.263636  0.262181  0.176380  0.161290  0.346154   \n",
       "2     0.083624  0.156863  0.300000  0.396752  0.191718  0.177419  0.355769   \n",
       "3     0.097561  0.107843  0.390909  0.201856  0.019939  0.451613  0.288462   \n",
       "4     0.073171  0.411765  0.445455  0.271462  0.007669  0.467742  0.413462   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3995  0.216028  0.098039  0.372727  0.415313  0.141104  0.419355  0.288462   \n",
       "3996  0.202091  0.147059  0.400000  0.375870  0.243865  0.177419  0.317308   \n",
       "3997  0.111498  0.156863  0.727273  0.278422  0.087423  0.387097  0.211538   \n",
       "3998  0.052265  0.215686  0.463636  0.292343  0.058282  0.677419  0.250000   \n",
       "3999  0.216028  0.176471  0.427273  0.443155  0.088957  0.225806  0.278846   \n",
       "\n",
       "         feat7     feat8     feat9  label  \n",
       "0     0.325581  0.166184  0.192771      6  \n",
       "1     0.255814  0.196453  0.301205      5  \n",
       "2     0.360465  0.226141  0.186747      6  \n",
       "3     0.372093  0.088490  0.216867      7  \n",
       "4     0.232558  0.128976  0.283133      5  \n",
       "...        ...       ...       ...    ...  \n",
       "3995  0.337209  0.155966  0.144578      6  \n",
       "3996  0.430233  0.229227  0.210843      6  \n",
       "3997  0.220930  0.144399  0.192771      5  \n",
       "3998  0.255814  0.103913  0.162651      6  \n",
       "3999  0.186047  0.164064  0.234940      6  \n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('store/data.csv', header=None)\n",
    "df.columns = [ f'feat{i:1d}' for i in range(10) ] + ['label']\n",
    "# df = df.convert_dtypes()\n",
    "df.label = df.label.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat0</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.116510</td>\n",
       "      <td>0.195335</td>\n",
       "      <td>0.425750</td>\n",
       "      <td>0.300546</td>\n",
       "      <td>0.089198</td>\n",
       "      <td>0.406244</td>\n",
       "      <td>0.293487</td>\n",
       "      <td>0.312828</td>\n",
       "      <td>0.133438</td>\n",
       "      <td>0.200724</td>\n",
       "      <td>5.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059493</td>\n",
       "      <td>0.099523</td>\n",
       "      <td>0.136702</td>\n",
       "      <td>0.098385</td>\n",
       "      <td>0.078084</td>\n",
       "      <td>0.199519</td>\n",
       "      <td>0.080470</td>\n",
       "      <td>0.132579</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.072472</td>\n",
       "      <td>0.893463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.232019</td>\n",
       "      <td>0.016871</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.088876</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.070552</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.153310</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.366589</td>\n",
       "      <td>0.142638</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.336538</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.173318</td>\n",
       "      <td>0.230422</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975807</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feat0        feat1        feat2        feat3        feat4  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean      0.116510     0.195335     0.425750     0.300546     0.089198   \n",
       "std       0.059493     0.099523     0.136702     0.098385     0.078084   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.073171     0.127451     0.327273     0.232019     0.016871   \n",
       "50%       0.111498     0.176471     0.418182     0.290023     0.070552   \n",
       "75%       0.153310     0.235294     0.509091     0.366589     0.142638   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             feat5        feat6        feat7        feat8        feat9  \\\n",
       "count  4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean      0.406244     0.293487     0.312828     0.133438     0.200724   \n",
       "std       0.199519     0.080470     0.132579     0.058018     0.072472   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.241935     0.240385     0.220930     0.088876     0.156627   \n",
       "50%       0.387097     0.288462     0.290698     0.128976     0.186747   \n",
       "75%       0.548387     0.336538     0.383721     0.173318     0.230422   \n",
       "max       0.975807     0.663462     1.000000     1.000000     0.740964   \n",
       "\n",
       "             label  \n",
       "count  4000.000000  \n",
       "mean      5.882000  \n",
       "std       0.893463  \n",
       "min       3.000000  \n",
       "25%       5.000000  \n",
       "50%       6.000000  \n",
       "75%       6.000000  \n",
       "max       9.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.label.plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "6    1773\n",
       "5    1185\n",
       "7     735\n",
       "8     147\n",
       "4     140\n",
       "3      16\n",
       "9       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.36      0.29      0.32        28\n",
      "           5       0.64      0.58      0.61       237\n",
      "           6       0.65      0.68      0.66       355\n",
      "           7       0.53      0.59      0.56       147\n",
      "           8       0.42      0.48      0.45        29\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       800\n",
      "   macro avg       0.37      0.37      0.37       800\n",
      "weighted avg       0.61      0.61      0.61       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/micromamba/envs/pb2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tornikeo/micromamba/envs/pb2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tornikeo/micromamba/envs/pb2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform sanity-checking\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "train, val = train_test_split(df, stratify=df.label, random_state=42, test_size=.2)\n",
    "train_x, train_y = train.drop(columns='label'), train['label']\n",
    "val_x, val_y = val.drop(columns='label'), val['label']\n",
    "\n",
    "knn.fit(train_x, train_y)\n",
    "val_pred = knn.predict(val_x)\n",
    "print(classification_report(val_y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.233449, 0.166667, 0.381818, ..., 0.325581, 0.166184, 0.192771],\n",
       "        [0.160279, 0.196078, 0.263636, ..., 0.255814, 0.196453, 0.301205],\n",
       "        [0.083624, 0.156863, 0.3     , ..., 0.360465, 0.226141, 0.186747],\n",
       "        ...,\n",
       "        [0.111498, 0.156863, 0.727273, ..., 0.22093 , 0.144399, 0.192771],\n",
       "        [0.052265, 0.215686, 0.463636, ..., 0.255814, 0.103913, 0.162651],\n",
       "        [0.216028, 0.176471, 0.427273, ..., 0.186047, 0.164064, 0.23494 ]]),\n",
       " array([6, 5, 6, ..., 5, 6, 6]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = df.drop(columns='label').to_numpy(), df.label.to_numpy()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,) (800,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.06      0.07      0.07        28\n",
      "           5       0.30      0.28      0.29       237\n",
      "           6       0.43      0.44      0.44       355\n",
      "           7       0.16      0.16      0.16       147\n",
      "           8       0.00      0.00      0.00        29\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       800\n",
      "   macro avg       0.14      0.14      0.14       800\n",
      "weighted avg       0.31      0.31      0.31       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy import stats\n",
    "\n",
    "class CuKNN(BaseEstimator):\n",
    "    def __init__(self, n_neighbors:int=5) -> None:\n",
    "        super().__init__()\n",
    "        self.n_neighbors = n_neighbors\n",
    "    def fit(self, x, y):\n",
    "        self.x = cp.array(x)\n",
    "        self.y = cp.array(y)\n",
    "        # if len(self.y.shape) == 1:\n",
    "        #     self.y = self.y[None, :]\n",
    "        return self\n",
    "    def predict(self, x):\n",
    "        x # Shape N, F\n",
    "        self.x # Shape M, F\n",
    "        # distances shape of N, M, d[i, j] = euclidean_norm(x[i, ...] - self.x[j, ...])\n",
    "        \n",
    "        dist = distance(self.x, x) # size N, M\n",
    "        k_idx = np.argsort(dist)[:self.n_neighbors] # size N, n_neigh\n",
    "        k_labels = self.y[k_idx].T.get()\n",
    "        return stats.mode(k_labels, axis=1, keepdims=False).mode\n",
    "        \n",
    "\n",
    "\n",
    "# Perform sanity-checking\n",
    "\n",
    "knn = CuKNN(n_neighbors=1)\n",
    "train, val = train_test_split(df, stratify=df.label, random_state=42, test_size=.2)\n",
    "train_x, train_y = train.drop(columns='label'), train['label']\n",
    "val_x, val_y = val.drop(columns='label'), val['label']\n",
    "\n",
    "knn.fit(train_x, train_y)\n",
    "val_pred = knn.predict(val_x)\n",
    "print(val_pred.shape, val_y.shape)\n",
    "print(classification_report(val_y, val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
